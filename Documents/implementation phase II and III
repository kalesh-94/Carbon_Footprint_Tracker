ğŸ› ï¸ Implementation Steps: 

ğŸ“Œ Step 1: Data Preprocessing & Feature Engineering
Before training our models, we ensured the dataset was clean, structured, and ready for machine learning:

âœ… Handled Missing Values:
- Categorical Data â†’ Replaced with the most frequent category (Mode).
- Numerical Data â†’ Filled using the Mean for a balanced distribution.

âœ… Feature Encoding:
- Applied One-Hot Encoding to transform categorical variables into numerical format.

âœ… Feature Scaling:
- Standardized numerical data using StandardScaler() to optimize model convergence.

âœ… Data Splitting:
- Split into 80% training data & 20% testing data to evaluate model generalization.



ğŸ“Œ Step 2: Model Training & Evaluation
We trained multiple machine learning models to compare their effectiveness in predicting carbon emissions. Each model was fine-tuned for optimal performance.

ğŸ“Œ Linear Regression (LR)
- A simple but effective baseline model.
- Helps understand the fundamental relationships in the dataset.

ğŸ“Œ MLP Regressor (Neural Network - NN)
- A deep learning approach using a multi-layer perceptron with (64,128,64) hidden layers.
- Activation Function: Tanh (for smooth transitions).
- Max Iterations: 436 to ensure proper convergence.

ğŸ“Œ Gradient Boosting Regressor (GBR)
- An ensemble learning method that combines multiple decision trees.
- Boosts performance by reducing both bias and variance.
- Final Choice due to superior accuracy and generalization.


ğŸ“Œ Step 3: Model Performance Analysis & Selection
Each model was evaluated using:
ğŸ”¹ Root Mean Square Error (RMSE): Measures prediction errorâ€”lower is better.
ğŸ”¹ RÂ² Score: Measures model accuracyâ€”closer to 1 is better.

ğŸ† Best Model: Gradient Boosting Regressor (GBR)
Outperformed Linear Regression & Neural Networks.
Achieved the lowest RMSE and highest RÂ² Score.







